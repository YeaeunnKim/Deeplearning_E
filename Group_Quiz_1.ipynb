{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgb0B8TONKBX4zpKB+EBD5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeaeunnKim/Deeplearning_E/blob/main/Group_Quiz_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Quiz 1"
      ],
      "metadata": {
        "id": "EQLiDyqTH8BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100 # number of data\n",
        "\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = (0.1 * np.random.randn(N, 1)) # normal distribution\n",
        "y = true_b + true_w * x + epsilon # data generation"
      ],
      "metadata": {
        "id": "TlJY4V6-M6AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffles the indices\n",
        "idx = np.arange(N)\n",
        "split_index = int(N * 0.8) # train-validation split\n",
        "\n",
        "train_idx = idx[:split_index]\n",
        "val_idx = idx[split_index:]\n",
        "\n",
        "# Generates train and validation sets: it can be replaced by \"train_test_split\"\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "ZwhfA2uINAKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# create tensor at GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)"
      ],
      "metadata": {
        "id": "8FUA9c8bNGkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "@timer\n",
        "def train_model_torch_optim(lr=0.1, epochs=1000):\n",
        "    # Initialize parameters\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    parameters = [b, w]\n",
        "    optimizer = optim.SGD(parameters, lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Loss computation\n",
        "        y_hat = b + w * x_train_tensor\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "\n",
        "        # Standard PyTorch code for training(Gradient computation and descent)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return b, w"
      ],
      "metadata": {
        "id": "nYyXwl7sNOmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat = train_model_torch_optim()\n",
        "print(\"b_estimate: {}, w_estimate: {}\".format(b_hat, w_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTFsWFe3NPN2",
        "outputId": "bcd5557c-43fc-4cdf-c60b-d850edd8f3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of train_model_torch_optim: 0.5571005344390869 seconds\n",
            "b_estimate: tensor([1.0234], device='cuda:0', requires_grad=True), w_estimate: tensor([1.9368], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_test_tensor = torch.as_tensor(x_val).to(device)\n",
        "y_test_tensor = torch.as_tensor(y_val).to(device)"
      ],
      "metadata": {
        "id": "nVcicjQeNnrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = b_hat + w_hat * x_test_tensor\n",
        "mse_loss = nn.MSELoss()\n",
        "loss = mse_loss(y_hat, y_test_tensor)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iez2V7wBNnuc",
        "outputId": "ffdbc050-f7be-48c5-8753-5288d67e07a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0098, device='cuda:0', dtype=torch.float64,\n",
              "       grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Quiz 2"
      ],
      "metadata": {
        "id": "Of_fVgEnOyUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/KUBIG/2023_summer/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRt9E_ooIcS8",
        "outputId": "e267834e-62b5-4a4a-b44a-a84448d3ff37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('quiz_data.pkl', 'rb') as f:\n",
        "    loaded_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "GNUN5TfSHIQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = loaded_dict['x']\n",
        "y = loaded_dict['y']"
      ],
      "metadata": {
        "id": "z95bjARQH-M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZnRmTJMH-O3",
        "outputId": "68fdd1a0-e783-489e-f66c-3c941edc8f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqjU4HrSLUIz",
        "outputId": "8603a206-c40b-4d55-f709-2de6da31613e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(x)\n",
        "idx = np.arange(N)\n",
        "split_index = int(N * 0.8)\n",
        "\n",
        "train_idx = idx[:split_index]\n",
        "val_idx = idx[split_index:]\n",
        "\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "Ch6Ecvt-H-Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create tensor at GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)"
      ],
      "metadata": {
        "id": "O2d3IascH-Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "@timer\n",
        "def train_model_torch_optim(lr=0.1, epochs=1000):\n",
        "    # Initialize parameters\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w3 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w5 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    parameters = [b, w, w3, w5]\n",
        "    optimizer = optim.SGD(parameters, lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Loss computation\n",
        "        y_hat = b + w * x_train_tensor + w3 * (x_train_tensor**3) + w5 * (x_train_tensor**5)\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "\n",
        "        # Standard PyTorch code for training(Gradient computation and descent)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return b, w, w3, w5"
      ],
      "metadata": {
        "id": "PrmchspDX9Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_test_tensor = torch.as_tensor(x_val).to(device)\n",
        "y_test_tensor = torch.as_tensor(y_val).to(device)"
      ],
      "metadata": {
        "id": "MPNr7YHtdkpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat, w3_hat, w5_hat = train_model_torch_optim()\n",
        "print(\"b_estimate: {}, w_estimate: {}, w3_estimate: {}, w5_estimate: {}\".format(b_hat, w_hat, w3_hat, w5_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nav_71A6YK23",
        "outputId": "763ad0f9-fcbc-4213-80ac-06c9974e6e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of train_model_torch_optim: 0.9077095985412598 seconds\n",
            "b_estimate: tensor([-0.7356], device='cuda:0', requires_grad=True), w_estimate: tensor([1.9018], device='cuda:0', requires_grad=True), w3_estimate: tensor([-1.6054], device='cuda:0', requires_grad=True), w5_estimate: tensor([-0.9603], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = b_hat + w_hat * x_test_tensor + w3_hat * (x_test_tensor**3) + w5_hat * (x_test_tensor**5)\n",
        "mse_loss = nn.MSELoss()\n",
        "loss = mse_loss(y_hat, y_test_tensor)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NAFl89Vdkvv",
        "outputId": "9cabd94c-3452-422f-ce92-7c89bcfda108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1503, device='cuda:0', dtype=torch.float64,\n",
              "       grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}